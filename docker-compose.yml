services:
  api:
    image: ${DOCKER_HUB_USERNAME}/rag-nodejs-api:latest
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
    depends_on:
      - ollama
      - weaviate
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    environment:
      - MODEL=llama3.2
    volumes:
      - ./data:/data
    restart: unless-stopped
  # Adding Weaviate as a vector database (Pinecone alternative for local development)
  weaviate:
    image: semitechnologies/weaviate:1.20.5
    ports:
      - "8081:8080"
    restart: unless-stopped
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers' # Change this from 'none' to match your code
      ENABLE_MODULES: 'text2vec-transformers' # Add this line
      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080' # Add this line
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
  t2v-transformers:
    image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1
    environment:
      ENABLE_CUDA: '0'
    restart: unless-stopped
volumes:
  weaviate_data:
