
# Verify Weaviate Schema
GET http://localhost:8081/v1/schema
Content-Type: application/json

###

POST http://localhost:3000/api/rag/generate
Content-Type: application/json

{
  "query": "What is Retrieval Augmented Generation?"
}

###

POST http://localhost:3000/api/rag/generate
Content-Type: application/json

{
  "query": "Explain the benefits of using Langchain with LLMs."
}

###
# Test Ollama directly
POST http://localhost:11434/api/generate
Content-Type: application/json

{
  "model": "llama3.2",
  "prompt": "Why is the sky blue?"
}

###
# Test Ollama directly - chat endpoint
POST http://localhost:11434/api/chat
Content-Type: application/json

{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}

###
# Test RAG API - insert endpoint
POST http://localhost:3000/api/rag/insert
Content-Type: application/json

{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "content": "Retrieval-Augmented Generation (RAG) is a technique that combines the strengths of retrieval-based methods and generative models.",
  "metadata": {
    "author": "Test User",
    "topic": "RAG"
  }
}

###

# Test RAG API - insert endpoint
POST http://localhost:3000/api/rag/insert
Content-Type: application/json

{
  "id": "123e4567-e89b-12d3-a456-426614174001",
  "content": "Langchain is a framework for developing applications powered by language models. It enables building context-aware and reasoning applications.",
  "metadata": {
    "author": "Test User",
    "topic": "Langchain"
  }
}

###

# Test RAG API - generate endpoint (similarity search)
POST http://localhost:3000/api/rag/generate
Content-Type: application/json

{
  "query": "What is RAG and how does it work?"
}

###

# Test RAG API - generate endpoint
POST http://localhost:3000/api/rag/generate
Content-Type: application/json

{
  "query": "Explain the benefits of using Langchain with LLMs."
}

###
# Test Ollama directly
POST http://localhost:11434/api/generate
Content-Type: application/json

{
  "model": "llama3.2",
  "prompt": "Why is the sky blue?"
}

###
# Test Ollama directly - chat endpoint
POST http://localhost:11434/api/chat
Content-Type: application/json

{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}

###
# Directly query Weaviate
POST http://localhost:8081/v1/graphql
Content-Type: application/json

{
  "query": "{ Get { Document { content metadata } } }"
}